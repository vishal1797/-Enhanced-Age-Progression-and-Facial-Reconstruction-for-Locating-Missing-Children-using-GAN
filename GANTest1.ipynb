{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce80b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishal\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "files ['1_0_3_20161220144649151.jpg', '1_0_3_20161220144657607.jpg', '1_0_3_20161220144712431.jpg', '1_0_3_20161220144830816.jpg', '1_0_3_20161220144835319.jpg', '1_0_3_20161220144838191.jpg', '1_0_3_20161220144949223.jpg', '1_0_3_20161220145001239.jpg']\n",
      "['C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144649151.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144657607.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144712431.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144830816.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144835319.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144838191.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220144949223.jpg', 'C:\\\\Users\\\\vishal\\\\Desktop\\\\Faceaging new 3\\\\testing\\\\Test/1_0_3_20161220145001239.jpg']\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg : 3\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg : 3\n",
      "output path Result//0.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg Result/1_0_3_20161220144649151.jpg\\cat1_1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg Result/1_0_3_20161220144649151.jpg\\cat2_1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg Result/1_0_3_20161220144649151.jpg\\cat3_1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg Result/1_0_3_20161220144649151.jpg\\cat4_1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144649151.jpg Result/1_0_3_20161220144649151.jpg\\cat5_1_0_3_20161220144649151.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg Result/1_0_3_20161220144657607.jpg\\cat1_1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg Result/1_0_3_20161220144657607.jpg\\cat2_1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg Result/1_0_3_20161220144657607.jpg\\cat3_1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg Result/1_0_3_20161220144657607.jpg\\cat4_1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144657607.jpg Result/1_0_3_20161220144657607.jpg\\cat5_1_0_3_20161220144657607.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg Result/1_0_3_20161220144712431.jpg\\cat1_1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg Result/1_0_3_20161220144712431.jpg\\cat2_1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg Result/1_0_3_20161220144712431.jpg\\cat3_1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg Result/1_0_3_20161220144712431.jpg\\cat4_1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144712431.jpg Result/1_0_3_20161220144712431.jpg\\cat5_1_0_3_20161220144712431.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg Result/1_0_3_20161220144830816.jpg\\cat1_1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg Result/1_0_3_20161220144830816.jpg\\cat2_1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg Result/1_0_3_20161220144830816.jpg\\cat3_1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg Result/1_0_3_20161220144830816.jpg\\cat4_1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144830816.jpg Result/1_0_3_20161220144830816.jpg\\cat5_1_0_3_20161220144830816.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg Result/1_0_3_20161220144835319.jpg\\cat1_1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg Result/1_0_3_20161220144835319.jpg\\cat2_1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg Result/1_0_3_20161220144835319.jpg\\cat3_1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg Result/1_0_3_20161220144835319.jpg\\cat4_1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144835319.jpg Result/1_0_3_20161220144835319.jpg\\cat5_1_0_3_20161220144835319.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg Result/1_0_3_20161220144838191.jpg\\cat1_1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg Result/1_0_3_20161220144838191.jpg\\cat2_1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg Result/1_0_3_20161220144838191.jpg\\cat3_1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg Result/1_0_3_20161220144838191.jpg\\cat4_1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144838191.jpg Result/1_0_3_20161220144838191.jpg\\cat5_1_0_3_20161220144838191.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg Result/1_0_3_20161220144949223.jpg\\cat1_1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg Result/1_0_3_20161220144949223.jpg\\cat2_1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg Result/1_0_3_20161220144949223.jpg\\cat3_1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg Result/1_0_3_20161220144949223.jpg\\cat4_1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220144949223.jpg Result/1_0_3_20161220144949223.jpg\\cat5_1_0_3_20161220144949223.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg Result/1_0_3_20161220145001239.jpg\\cat1_1_0_3_20161220145001239.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg Result/1_0_3_20161220145001239.jpg\\cat2_1_0_3_20161220145001239.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg Result/1_0_3_20161220145001239.jpg\\cat3_1_0_3_20161220145001239.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg Result/1_0_3_20161220145001239.jpg\\cat4_1_0_3_20161220145001239.jpg\n",
      "C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\\Test/1_0_3_20161220145001239.jpg Result/1_0_3_20161220145001239.jpg\\cat5_1_0_3_20161220145001239.jpg\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch import autograd\n",
    "from misc import *\n",
    "from PIL import ImageFile\n",
    "\n",
    "\n",
    "import os.path\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import random\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "\n",
    "# torch.cuda.set_device('cuda:0')\n",
    "\n",
    "\n",
    "layer_names = ['conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "               'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "               'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3', 'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "               'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3', 'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "               'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3', 'relu5_3', 'conv5_4', 'relu5_4', 'pool5']\n",
    "               \n",
    "content_layers = ['relu1_1', 'relu2_1', 'relu3_1']\n",
    "\n",
    "\n",
    "\n",
    "#use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "n_z = 50\n",
    "n_l = 5\n",
    "n_channel = 3\n",
    "n_disc = 16\n",
    "n_gen = 64\n",
    "nef = 64\n",
    "ndf = 64\n",
    "ngpu = 1\n",
    "n_z = 50\n",
    "n_l = 5\n",
    "n_channel = 3\n",
    "n_disc = 16\n",
    "n_gen = 64\n",
    "n_age = int(n_z/n_l) #12\n",
    "n_gender = int(n_z/2) #25\n",
    "image_size = 128\n",
    "nz = int(n_z)\n",
    "nef = int(nef)\n",
    "ndf = int(ndf)\n",
    "nc = 3\n",
    "out_size = image_size // 16  # 64\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Self Attection Block\n",
    "class Self_Attn(nn.Module):\n",
    "    def __init__(self,in_dim,activation):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.action = activation\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim//8,kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim,out_channels=in_dim,kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "    def forward(self,x):\n",
    "        m_batchsize,C,width,height = x.size()\n",
    "        \n",
    "        proj_query = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize,-1,width*height)\n",
    "        energy = torch.bmm(proj_query,proj_key) #batch matrix-matrix product of matrices store\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value  = self.value_conv(x).view(m_batchsize,-1,width*height)\n",
    "        out  = torch.bmm(proj_value,attention.permute(0,2,1))\n",
    "        out  = out.view(m_batchsize,C,width,height)\n",
    "        out = self.gamma*out +x\n",
    "        return out,attention\n",
    "\n",
    "\n",
    "# Residule Block\n",
    "class resnet_block(nn.Module):\n",
    "    def __init__(self, channel, kernel, stride, padding):\n",
    "        super(resnet_block, self).__init__()\n",
    "        self.channel = channel\n",
    "        self.kernel = kernel\n",
    "        self.strdie = stride\n",
    "        self.padding = padding\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv1_norm = nn.BatchNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv2_norm = nn.BatchNorm2d(channel)\n",
    "        #self.initialize_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.conv1_norm(self.conv1(input)), True)\n",
    "        x = self.conv2_norm(self.conv2(x))\n",
    "\n",
    "        return input + x  # Elementwise Sum\n",
    "\n",
    "\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, nef, 4, 2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(nef, nef * 2, 4, 2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.encoder_second = nn.Sequential(\n",
    "            nn.Conv2d(nef * 2, nef * 4, 4, 2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(nef * 4, nef * 8, 4, 2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.resnet_blocks = []\n",
    "        for i in range(9):\n",
    "            self.resnet_blocks.append(resnet_block(nef * 2, 3, 1, 1))\n",
    "\n",
    "        self.resnet_blocks = nn.Sequential(*self.resnet_blocks)\n",
    "        self.attn1  = Self_Attn(512,'relu')\n",
    "        self.mean = nn.Linear(nef * 8 * out_size * out_size, nz)\n",
    "        self.logvar = nn.Linear(nef * 8 * out_size * out_size, nz)\n",
    "\n",
    "    def sampler(self, mean, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mean)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        \n",
    "        hidden = self.encoder(input)\n",
    "        hidden = self.resnet_blocks(hidden)\n",
    "        hidden = self.encoder_second(hidden)\n",
    "        \n",
    "        out,ep1  = self.attn1(hidden)\n",
    "        \n",
    "        hidden = out.view(batch_size, -1)\n",
    "        mean, logvar = self.mean(hidden), self.logvar(hidden)\n",
    "        latent_z = self.sampler(mean, logvar)\n",
    "        return latent_z,ep1\n",
    "encoder = Encoder()\n",
    "\n",
    "# Decoder \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    " \n",
    "        self.decoder_dense = nn.Sequential(\n",
    "            nn.Linear(n_z+n_l*n_age+n_gender, ndf * 8 * out_size * out_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(ndf * 8, ndf * 4, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(ndf * 4, ndf * 2, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(ndf * 2, ndf, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(ndf, nc, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, z,age,gender):\n",
    "        batch_size = z.size(0)\n",
    "        l = age.repeat(1, n_age)  # size = 20 * 48\n",
    "        k = gender.view(-1, 1).repeat(1, n_gender)  # size = 20 * 25\n",
    "        x = torch.cat([z, l, k.float()], dim=1)  # size = 20 * 123\n",
    "        hidden = self.decoder_dense(x).view(batch_size,ndf * 8, out_size, out_size)\n",
    "        output = self.decoder_conv(hidden)\n",
    "        return output\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "    \n",
    "    \n",
    "# Load the train encoder and decoder model weights    \n",
    "c = torch.load(r'C:\\Users\\vishal\\Desktop\\Faceaging new 3\\Path of Output\\encoder_epoch_0.pth')\n",
    "encoder.load_state_dict(c)\n",
    "d = torch.load(r'C:\\Users\\vishal\\Desktop\\Faceaging new 3\\Path of Output\\decoder_epoch_0.pth')\n",
    "decoder.load_state_dict(d)\n",
    "\n",
    "outf=\"Result/\"\n",
    "if not os.path.exists(outf):\n",
    "    os.mkdir(outf)\n",
    "\n",
    "def get_loader(img_dir,label,batch_size=2,img_size=128,mode=\"train\",num_workers=1):\n",
    "    transform=[]\n",
    "    transform.append(transforms.Resize(img_size))\n",
    "    transform.append(transforms.ToTensor())\n",
    "    transform.append(transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = transforms.Compose(transform)\n",
    "    file_list=[]\n",
    "    for dir in os.listdir(img_dir):\n",
    "        print(dir)\n",
    "        path, dirs, files = next(os.walk((os.path.join(img_dir, dir))))\n",
    "        print(\"files\",files)\n",
    "        if (len(files) == 1):\n",
    "            pass\n",
    "        else:\n",
    "            for file in os.listdir(os.path.join(img_dir, dir)):\n",
    "                file_list.append(os.path.join(img_dir, dir)+\"/\"+file)\n",
    "\n",
    "    filenames = []\n",
    "    unchanged_target_ages = []\n",
    "    images = []\n",
    "    targets = []\n",
    "    target_genders = np.ones((len(file_list), 1), dtype=np.int32) * -1\n",
    "    for line in file_list:\n",
    "\n",
    "        image = Image.open(line)\n",
    "        image = transform(image)\n",
    "        images.append(np.array(image))\n",
    "    images = np.array(images)\n",
    "    return  images,file_list\n",
    "\n",
    "#  Test is directory\n",
    "images,file_list=  get_loader(img_dir=r\"C:\\Users\\vishal\\Desktop\\Faceaging new 3\\testing\",img_size=128,label=0,batch_size=8)\n",
    "print(file_list)\n",
    "images = torch.FloatTensor(images)\n",
    "batch_size = 8\n",
    "import math\n",
    "import scipy.misc\n",
    "num_batches = int(math.ceil(images.shape[0]/batch_size))\n",
    "i=0\n",
    "for batch in range(num_batches):\n",
    "    batch_image = images[batch*batch_size:(batch+1)*batch_size,:,:,:].repeat(5, 1, 1, 1)\n",
    "    file_batch = file_list[batch*batch_size:(batch+1)*batch_size]\n",
    "    fixed_l = -torch.ones(40 * 5).view(40, 5)\n",
    "    for i, l in enumerate(fixed_l):\n",
    "        l[i // 8] = 1\n",
    "    fixed_z,ep1 = encoder(batch_image)\n",
    "    target_genders = -torch.ones(batch_size*1).view(batch_size,1)\n",
    "    fcount=0\n",
    "    for file_name  in file_batch:\n",
    "        print(file_name)\n",
    "        \n",
    "        target_gender = int(file_name.split(\"/\")[-1].split(\"_\")[2])\n",
    "        print(file_name,\":\",target_gender)\n",
    "        \n",
    "        if (target_gender == 1):\n",
    "            target_genders[fcount] = 1\n",
    "        fcount=fcount+1\n",
    "    fixed_g= target_genders.view(-1, 1).repeat(5, 1)\n",
    "    fixed_g_v = Variable(fixed_g)\n",
    "    fixed_l_v = Variable(fixed_l)\n",
    "    fixed_fake = decoder(fixed_z,fixed_l_v,fixed_g_v)\n",
    "    outputpath = outf+\"/\"+str(batch)+\".jpg\"\n",
    "    vutils.save_image(fixed_fake.data,outputpath , normalize=True)\n",
    "    print(\"output path\",outputpath)\n",
    "    img = Image.open(outputpath)\n",
    "    noOfRow = 5\n",
    "    noOfColumn = 8\n",
    "    x1 = 2\n",
    "    y1 = 2\n",
    "    x2 = 130\n",
    "    y2 = 130\n",
    "    folder = file_batch\n",
    "    # Store result according the test image id.\n",
    "    for i in range(0, noOfColumn):\n",
    "        dest_dir = file_batch[i].split(\"/\")[-1]\n",
    "        if not os.path.exists(outf+\"/\"+dest_dir):\n",
    "            os.mkdir(outf+\"/\"+dest_dir)\n",
    "        for j in range(1, noOfRow + 1):\n",
    "            area = (x1, y1, x2, y2)\n",
    "            cropped_img = img.crop(area)\n",
    "            imgName = \"{}{}\".format(i, j)\n",
    "            if(int(imgName)==1 or int(imgName)==11 or int(imgName)==21 or int(imgName)==31 or int(imgName)==41 or int(imgName)==51 or int(imgName)==61 or int(imgName)==71):\n",
    "                filename= \"cat1_\"+file_batch[i].split(\"/\")[-1]\n",
    "                shutil.copy(file_batch[i],os.path.join(outf+dest_dir,file_batch[i].split(\"/\")[-1]))\n",
    "                \n",
    "            if (int(imgName) == 2 or int(imgName) == 12 or int(imgName) == 22 or int(imgName) == 32 or int(imgName) == 42 or int(imgName) == 52 or int(imgName) == 62 or int(imgName) == 72):\n",
    "                filename = \"cat2_\" + file_batch[i].split(\"/\")[-1]\n",
    "            if (int(imgName) == 3 or int(imgName) == 13 or int(imgName) == 23 or int(imgName) == 33 or int(imgName) == 43 or int(imgName) == 53 or int(imgName) == 63 or int(imgName) == 73):\n",
    "                filename = \"cat3_\" + file_batch[i].split(\"/\")[-1]\n",
    "            if (int(imgName) == 4 or int(imgName) == 14 or int(imgName) == 24 or int(imgName) == 34 or int(imgName) == 44 or int(imgName) == 54 or int(imgName) == 64 or int(imgName) == 74):\n",
    "                filename = \"cat4_\" + file_batch[i].split(\"/\")[-1]\n",
    "            if (int(imgName) == 5 or int(imgName) == 15 or int(imgName) == 25 or int(imgName) == 35 or int(imgName) == 45 or int(imgName) == 55 or int(imgName) == 65 or int(imgName) == 75):\n",
    "                filename = \"cat5_\" + file_batch[i].split(\"/\")[-1]\n",
    "            print(file_batch[i],os.path.join(outf+dest_dir,filename))\n",
    "            cropped_img.save(os.path.join(outf+dest_dir,filename))\n",
    "            y1 = y1 + 130\n",
    "            y2 = y2 + 130\n",
    "        x1 = x1 + 130\n",
    "        x2 = x2 + 130\n",
    "        y1 = 2\n",
    "        y2 = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491f02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
